{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb2e25b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    " \n",
    "def get_logger(filename, verbosity=1, name=None):\n",
    "    level_dict = {0: logging.DEBUG, 1: logging.INFO, 2: logging.WARNING}\n",
    "    formatter = logging.Formatter(\n",
    "        \"[%(asctime)s][%(filename)s][line:%(lineno)d][%(levelname)s] %(message)s\"\n",
    "    )\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level_dict[verbosity])\n",
    " \n",
    "    fh = logging.FileHandler(filename, \"w\")\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)\n",
    " \n",
    "    sh = logging.StreamHandler()\n",
    "    sh.setFormatter(formatter)\n",
    "    logger.addHandler(sh)\n",
    " \n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c92a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import tqdm\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Make plots inline\n",
    "%matplotlib inline\n",
    "import urllib.request\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from math import floor\n",
    "from utils.tools import StandardScaler\n",
    "\n",
    "#test Razvan's model\n",
    "from models.ours import PA\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def setup_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "# set seed\n",
    "setup_seed(42)\n",
    "\n",
    "# this is for running the notebook in our testing framework\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
    "num_nodes = 1\n",
    "\n",
    "whole_data = np.load('./data/M4.npy', allow_pickle=True) ##\n",
    "#[\"Yearly\", \"Quarterly\", \"Monthly\", \"Weekly\", \"Daily\", \"Hourly\"]\n",
    "experiments = {\"Yearly\":6, \"Quarterly\":8, \"Monthly\":18, \"Weekly\":13, \"Daily\":14, \"Hourly\":48}\n",
    "exp_name = \"Yearly\"\n",
    "pre_horizon = experiments[exp_name]\n",
    "results = np.zeros([10,3], dtype=np.float32)\n",
    "order = 0\n",
    "seq_len, pred_len = 2*pre_horizon, 1\n",
    "output_dim = 1\n",
    "attention = 0\n",
    "\n",
    "for item in whole_data.item():\n",
    "        \n",
    "    if exp_name in item:\n",
    "        \n",
    "        print(item)\n",
    "        data = whole_data.item()[item]\n",
    "        print(len(data))\n",
    "        train_end = int((70. / 100.) * len(data))\n",
    "        test_end = int((90. / 100.) * len(data))\n",
    "        train_data = data[:train_end]\n",
    "        mean = np.mean(train_data)\n",
    "        std = np.std(train_data)\n",
    "        data = (data - mean)/std \n",
    "        data = torch.from_numpy(data)\n",
    "        train_data = torch.cat((torch.zeros((seq_len-1,)),data[:train_end]), axis=0)\n",
    "        valid_data = torch.cat((torch.zeros((seq_len-1,)),data[test_end:]), axis=0)\n",
    "        test_data = torch.cat((torch.zeros((seq_len-1,)),data[train_end:test_end]), axis=0)\n",
    "        train_data = train_data.unfold(0, seq_len+pred_len, 1).unsqueeze(-1)\n",
    "        valid_data = valid_data.unfold(0, seq_len+pred_len, 1).unsqueeze(-1)\n",
    "        test_data = test_data.unfold(0, seq_len+pred_len, 1).unsqueeze(-1)\n",
    "        train_x = train_data[:,:seq_len][::]\n",
    "        train_y = train_data[:,seq_len:].squeeze()\n",
    "        test_x = test_data[:-pre_horizon+1,:seq_len]\n",
    "        test_y = test_data[:-pre_horizon+1,seq_len:].squeeze()\n",
    "        val_x = valid_data[:,:seq_len]\n",
    "        val_y = valid_data[:,seq_len:].squeeze()\n",
    "        test = test_data\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            train_x, train_y, test_x, test_y = train_x.cuda(), train_y.cuda(), test_x.cuda(), test_y.cuda()\n",
    "            test = test.cuda()\n",
    "            val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "            \n",
    "        print(train_x.shape, train_y.shape, test_x.shape, test_y.shape, val_x.shape, val_y.shape, test.shape)\n",
    "    \n",
    "        feature_extractor = PA(horizon=pred_len, lag=seq_len, dynamic=False, supports=None,\n",
    "                               patch_sizes=[1], channels=32, num_nodes=num_nodes, \n",
    "                               input_dim=1, output_dim=1, device='cuda:0')\n",
    "\n",
    "        ##########################################################################################\n",
    "        \n",
    "        base_kernel_set = [gpytorch.kernels.ScaleKernel(gpytorch.kernels.LinearKernel()),\\\n",
    "                           gpytorch.kernels.ScaleKernel(gpytorch.kernels.PeriodicKernel()),\\\n",
    "                           gpytorch.kernels.ScaleKernel(gpytorch.kernels.RQKernel()),\\\n",
    "                           gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())]\n",
    "        R = 1\n",
    "        \n",
    "        final_kernel = 0\n",
    "        for i in range(R):\n",
    "            #this_iter = base_kernel_set.copy()\n",
    "            add_kernel = copy.deepcopy(base_kernel_set[0])\n",
    "            for j in range(1,len(base_kernel_set)):\n",
    "                add_kernel += copy.deepcopy(base_kernel_set[j])\n",
    "            add_kenrel = gpytorch.kernels.ScaleKernel(add_kernel)\n",
    "\n",
    "            if i == 0:\n",
    "                mul_kernel = copy.deepcopy(add_kernel)\n",
    "                final_kernel = copy.deepcopy(mul_kernel)\n",
    "                continue\n",
    "            else:\n",
    "                mul_kernel *= copy.deepcopy(add_kernel)\n",
    "                final_kernel += copy.deepcopy(mul_kernel)\n",
    "        \n",
    "        \n",
    "        print(final_kernel)\n",
    "    \n",
    "        '''\n",
    "        final_kernel =  gpytorch.kernels.ScaleKernel(gpytorch.kernels.PeriodicKernel()) + \\\n",
    "                        gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel()) + \\\n",
    "                        gpytorch.kernels.ScaleKernel(gpytorch.kernels.PeriodicKernel()*gpytorch.kernels.PeriodicKernel()) + \\\n",
    "                        gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel()*gpytorch.kernels.PeriodicKernel()) + \\\n",
    "                        gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel()*gpytorch.kernels.RBFKernel())\n",
    "        '''\n",
    "        ##########################################################################################\n",
    "        setup_seed(42)\n",
    "\n",
    "        idx = []\n",
    "        # The forward method\n",
    "        from gpytorch.models import ApproximateGP\n",
    "\n",
    "        class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "                def __init__(self, train_x, train_y, likelihood):\n",
    "                    super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "                    self.mean_module = gpytorch.means.ConstantMean()\n",
    "                    self.covar_module = final_kernel\n",
    "                    self.scale_to_bounds = gpytorch.utils.grid.ScaleToBounds(-1., 1.)\n",
    "                    self.feature_extractor = feature_extractor\n",
    "\n",
    "                def forward(self, x): ##\n",
    "                    global attention\n",
    "                    projected_x, attention = self.feature_extractor(x)\n",
    "                    projected_x = projected_x.squeeze()\n",
    "                    projected_x = projected_x.reshape(-1)\n",
    "                    mean_x = self.mean_module(projected_x)\n",
    "                    covar_x = self.covar_module(projected_x)\n",
    "                    return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "        likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        model = MultitaskGPModel(train_x, train_y, likelihood) \n",
    "\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            model = model.cuda()\n",
    "            likelihood = likelihood.cuda()\n",
    "            \n",
    "        ##########################################################################################\n",
    "        # setup_seed(42)\n",
    "\n",
    "        # Training the model\n",
    "        training_iterations = 300\n",
    "\n",
    "        # Use the adam optimizer\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "        #optimizer = torch.optim.Adam([\n",
    "        #    {'params': model.feature_extractor.parameters()},\n",
    "        #    {'params': model.covar_module.parameters()},\n",
    "        #    {'params': model.mean_module.parameters()},\n",
    "        #    {'params': model.likelihood.parameters()},\n",
    "        #], lr=0.001)\n",
    "\n",
    "        # \"Loss\" for GPs - the marginal log likelihood\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "        min_val_loss = 9999\n",
    "        flag = 0\n",
    "        torch.save(model.state_dict(), \"./saved/Trigp/ETTh1.pth\")\n",
    "        original = model.covar_module\n",
    "        retrain = 0\n",
    "        #recorder[0] = 1\n",
    "        #logger = get_logger('./log/'+'Trigp_M4_'+ exp_name +'.log')\n",
    "\n",
    "        def train():\n",
    "            patience = 150\n",
    "            counter = 0\n",
    "            val_losses = []\n",
    "\n",
    "            iterator = tqdm.notebook.tqdm(range(training_iterations))\n",
    "            for i in iterator:\n",
    "                # Find optimal model hyperparameters\n",
    "                model.train()\n",
    "                likelihood.train()\n",
    "\n",
    "                # Zero backprop gradients\n",
    "                optimizer.zero_grad()\n",
    "                # Get output from model\n",
    "                outputs = model(train_x)\n",
    "                # Calc loss and backprop derivatives\n",
    "                train_loss = -mll(outputs, train_y)\n",
    "                train_loss.backward()\n",
    "                iterator.set_postfix(train_loss=train_loss.item())\n",
    "                optimizer.step()\n",
    "                #logger.info('Epoch:[{}/{}]\\t loss={:.5f}'.format(i , training_iterations, train_loss))\n",
    "\n",
    "                model.eval()\n",
    "                likelihood.eval()\n",
    "                with torch.no_grad():\n",
    "                    preds = model(val_x)\n",
    "                    val_loss = -mll(preds, val_y)\n",
    "                    val_losses.append(val_loss)\n",
    "\n",
    "                global min_val_loss\n",
    "                if min_val_loss > val_loss and val_loss > 0:\n",
    "                    min_val_loss = val_loss\n",
    "                    global flag\n",
    "                    global original\n",
    "                    original = model.covar_module\n",
    "                    flag = 1\n",
    "                    #print(min_val_loss)\n",
    "                    if retrain == 1:\n",
    "                        print(\"Saving...\")\n",
    "                        torch.save(model.state_dict(), \"./saved/Trigp/ETTh1.pth\")\n",
    "                    counter = 0\n",
    "                else:\n",
    "                    counter += 1\n",
    "                    if counter % 10 == 0:\n",
    "                        for params in optimizer.param_groups:\n",
    "                            params['lr'] *= 0.9\n",
    "                            print(params['lr'])\n",
    "\n",
    "                if counter == patience:\n",
    "                    break\n",
    "\n",
    "\n",
    "        starttime = datetime.datetime.now()\n",
    "        train()\n",
    "        endtime = datetime.datetime.now()\n",
    "        print(\"time:\", (endtime - starttime).seconds)\n",
    "        #logger.info('finish training!')\n",
    "        \n",
    "        ##########################################################################################\n",
    "        ## Retrain:\n",
    "        retrain = 1\n",
    "        constrains = []\n",
    "        for constraint_name, constraint in model.named_constraints():\n",
    "            constrains.append(constraint)\n",
    "\n",
    "\n",
    "        index = 0\n",
    "        d = len(base_kernel_set)\n",
    "        a1 = len(base_kernel_set)\n",
    "        an = a1+(R-1)*d\n",
    "        length = int((a1+an)*R/2)\n",
    "        kernel_weights = torch.zeros(length)\n",
    "        for param_name, param in model.named_parameters():\n",
    "            if 'covar_module' and 'raw_outputscale' in param_name:\n",
    "                #print(f'Parameter name: {param_name:42}')\n",
    "                param_name = param_name.split('.')\n",
    "                constrain = constrains[index]\n",
    "                kernel_weights[index] = constraint.transform(param)\n",
    "                index += 1\n",
    "                #print(constraint.transform(param))\n",
    "\n",
    "        pre = 0\n",
    "        now = a1\n",
    "        numbers = 1\n",
    "        best_kernel_index = torch.zeros((R,numbers)).int()\n",
    "        for r in range(R):\n",
    "            weights = kernel_weights[pre:pre+d]\n",
    "            pre = now\n",
    "            now = a1 + a1+(r+1)*d\n",
    "            weights = nn.functional.softmax(weights, dim=0)\n",
    "            _, kernel_index = torch.sort(weights, descending=True)\n",
    "            best_kernel_index[r] = kernel_index[:numbers]\n",
    "\n",
    "        #print(best_kernel_index)\n",
    "        ####################################################################################\n",
    "\n",
    "        final_kernel = 0\n",
    "        for i in range(R):\n",
    "            add_kernel = copy.deepcopy(base_kernel_set[best_kernel_index[i][0]])\n",
    "            for j in range(1, numbers):\n",
    "                add_kernel += copy.deepcopy(base_kernel_set[best_kernel_index[i][j]])\n",
    "\n",
    "            if i == 0:\n",
    "                mul_kernel = copy.deepcopy(add_kernel)\n",
    "                final_kernel = copy.deepcopy(mul_kernel)\n",
    "                continue\n",
    "            else:\n",
    "                mul_kernel *= copy.deepcopy(add_kernel)\n",
    "                final_kernel += copy.deepcopy(mul_kernel)\n",
    "\n",
    "\n",
    "        print(final_kernel)\n",
    "        \n",
    "        min_val_loss = 9999\n",
    "        flag = 0\n",
    "        model.covar_module = final_kernel.cuda()\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "        #torch.save(model.state_dict(), \"./saved/Trigp/ETTh1.pth\")\n",
    "        starttime = datetime.datetime.now()\n",
    "        train()\n",
    "        endtime = datetime.datetime.now()\n",
    "        print(\"Retrain time:\", (endtime - starttime).seconds)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ##########################################################################################\n",
    "        import warnings\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        import seaborn as sns\n",
    "        setup_seed(42)\n",
    "\n",
    "        from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "        #model.load_state_dict(torch.load(\"./saved/Trigp/ETTh1.pt\"))\n",
    "\n",
    "        # Making Predictions\n",
    "        MAE = []\n",
    "        RMSE = []\n",
    "        MAPE = []\n",
    "        model.load_state_dict(torch.load(\"./saved/Trigp/ETTh1.pth\"))\n",
    "        model.eval()\n",
    "        likelihood.eval()\n",
    "\n",
    "        with torch.no_grad(), gpytorch.settings.use_toeplitz(False), gpytorch.settings.fast_pred_var():\n",
    "            for i in range(pre_horizon):\n",
    "                if i == 0:\n",
    "                    test_x = test[i:-pre_horizon+i,:seq_len].clone()\n",
    "                test_y = test[i:-pre_horizon+i,seq_len:,].squeeze().clone()\n",
    "\n",
    "                preds = model(test_x)\n",
    "                real_preds = preds.mean\n",
    "                real_test_y = test_y\n",
    "                real_test_y = real_test_y\n",
    "\n",
    "                rmse = mean_squared_error(real_test_y.cpu(), real_preds.cpu())\n",
    "                mae = mean_absolute_error(real_test_y.cpu(), real_preds.cpu())\n",
    "                real_preds = real_preds*std+mean\n",
    "                real_test_y = real_test_y*std+mean\n",
    "                '''\n",
    "                if i == 0:\n",
    "                    hehe = preds\n",
    "                    plt.plot(real_preds.cpu(), 'b', label=\"preds\")\n",
    "                    plt.plot(real_test_y.cpu(), 'r', label=\"real\")\n",
    "                '''\n",
    "                mape = mean_absolute_percentage_error(real_test_y.cpu(), real_preds.cpu())\n",
    "                MAE.append(mae)\n",
    "                RMSE.append(rmse)\n",
    "                MAPE.append(mape)\n",
    "                \n",
    "                if i == pre_horizon-1:\n",
    "                    break\n",
    "                test_x = torch.cat([test_x.squeeze().clone(), preds.mean.unsqueeze(-1)], axis=1)\n",
    "                test_x = test_x[:,1:].unsqueeze(-1).clone()\n",
    "\n",
    "        mae = np.array(MAE).mean()\n",
    "        rmse = np.array(RMSE).mean()\n",
    "        mape = np.array(MAPE).mean()\n",
    "        print('Test predict MAE, RMSE, MAPE:', mae, rmse**0.5, mape)\n",
    "        results[order][0] = mae\n",
    "        results[order][1] = rmse**0.5\n",
    "        results[order][2] = mape\n",
    "        model_path = \"./model_and_weights/M4/trigp_NAS/\" + item + \".pkl\"\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        order += 1\n",
    "        \n",
    "\n",
    "print(results)\n",
    "print(np.mean(results, axis=0))\n",
    "#print(recorder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca77c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "print(np.mean(results, axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
